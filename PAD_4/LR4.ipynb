{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dde52825",
      "metadata": {
        "id": "dde52825",
        "outputId": "3b5f5c02-a30f-46ee-8c5a-25c078543d75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#!pip install pymorphy2==0.8\n",
        "#!pip install pymystem3\n",
        "\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
        "#from pymorphy2 import MorphAnalyzer\n",
        "from pymystem3 import Mystem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf35e32c",
      "metadata": {
        "id": "bf35e32c",
        "outputId": "1c965a9e-fba3-4e5c-f7c9-742ca5ebc93e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 text     label  \\\n",
            "0   –ü–æ–º–æ–π–º—É —è –≤–∫—Ä–∞—à–∏–ª–∞—Å—å –≤ –ß–∏–º–∏–Ω–∞ü§ß https://t.co/t2...  positive   \n",
            "5                       @buybread_ —è –Ω–µ —Å –ø–æ—Ä—è–¥–∫–µ!!!!  negative   \n",
            "10  @ange1flyhigh –í —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑ –±—É–¥—É –¥–æ –ø–æ–±–µ–¥–Ω–æ–≥...  positive   \n",
            "15  @LimitaVIP –£–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–π –≥i–º–Ω...\\r\\n–£–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ...  negative   \n",
            "17                            —è —Å—Ä–∞–ª–∞ –Ω–∞ —ç—Ç—É –±–∏–æ–ª–æ–≥–∏—é  negative   \n",
            "\n",
            "                     id  \n",
            "0   1282311169534038016  \n",
            "5   1335130757044563971  \n",
            "10  1215370396465291267  \n",
            "15  1253799540848762887  \n",
            "17  1339418979887173632  \n",
            "                                                text     label  \\\n",
            "1      —è —Å—á–∏—Ç–∞—é —ç—Ç–æ –º–µ–º –≥–æ–¥–∞ https://t.co/xoVKj5y8Mj  positive   \n",
            "2  —è–Ω —Ä—É—Å—Å–∫–∏–π –Ω–∞ —Å–æ—Ç–∫—É –≤—Å–µ –∑–∞–ø—è—Ç—ã–µ –≥–¥–µ –Ω–∞–¥–æü§ôüèªüëçüèªüëçüèª...  positive   \n",
            "5  (–ø—É—à–∫–∞ –Ω–∞ –ö–∞—Ä–∞—É–ª—å–Ω–æ–π –≥–æ—Ä–µ –±–æ–ª—å—à–µ –Ω–µ —Å—Ç—Ä–µ–ª—è–µ—Ç –ë...  negative   \n",
            "6      @Iori_loves_U –ö–∞–∫ –º–∏–ª–æ /—Å–º—É—Ç–∏–ª–∞—Å—å/ —Å–ø–∞—Å–∏–±–æ ü•∞üå∏  positive   \n",
            "9        –º–Ω–µ –±–æ–ª—å–Ω–æ –¥—ã—à–∞—Ç—å..—è –∫–∞–∫ –±–∞–±–∫–∞ 80 –ª–µ—Ç —É–∂–∞—Åüö¨  negative   \n",
            "\n",
            "                    id  \n",
            "1  1218052288964632576  \n",
            "2  1212859589592539136  \n",
            "5  1342696727808274432  \n",
            "6  1317052132382679041  \n",
            "9  1318122321622818816  \n"
          ]
        }
      ],
      "source": [
        "# –°—á–∏—Ç–∞–µ–º –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
        "train_data = pd.read_csv('rusentitweet_train.csv')\n",
        "test_data = pd.read_csv('rusentitweet_test.csv')\n",
        "\n",
        "determined_labels = ['positive', 'negative']\n",
        "\n",
        "filtered_train_data = train_data[train_data['label'].isin(determined_labels)]\n",
        "print(filtered_train_data.head())\n",
        "\n",
        "filtered_test_data = test_data[test_data['label'].isin(determined_labels)]\n",
        "print(filtered_test_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef4b0d9",
      "metadata": {
        "id": "4ef4b0d9",
        "outputId": "02813a75-8f2f-4aa5-bb91-6fa71e4fc13a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 text     label  \\\n",
            "0                     –ø–æ–º–æ–π–º—É —è –≤–∫—Ä–∞—à–∏–ª–∞—Å—å –≤ —á–∏–º–∏–Ω–∞ü§ß   positive   \n",
            "5                                  —è –Ω–µ —Å –ø–æ—Ä—è–¥–∫–µ!!!!  negative   \n",
            "10  –≤ —Å–ª–µ–¥—É—é—â–∏–π —Ä–∞–∑ –±—É–¥—É –¥–æ –ø–æ–±–µ–¥–Ω–æ–≥–æ –µ–µ –∑–∞–∫—Ä—ã–≤–∞—Ç—å...  positive   \n",
            "15  —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–π –≥i–º–Ω   \\r\\n—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ  —á—Ç–æ –ø–æ–∫–∞ ...  negative   \n",
            "17                            —è —Å—Ä–∞–ª–∞ –Ω–∞ —ç—Ç—É –±–∏–æ–ª–æ–≥–∏—é  negative   \n",
            "\n",
            "                     id  \n",
            "0   1282311169534038016  \n",
            "5   1335130757044563971  \n",
            "10  1215370396465291267  \n",
            "15  1253799540848762887  \n",
            "17  1339418979887173632  \n",
            "                                                text     label  \\\n",
            "1                             —è —Å—á–∏—Ç–∞—é —ç—Ç–æ –º–µ–º –≥–æ–¥–∞   positive   \n",
            "2  —è–Ω —Ä—É—Å—Å–∫–∏–π –Ω–∞ —Å–æ—Ç–∫—É –≤—Å–µ –∑–∞–ø—è—Ç—ã–µ –≥–¥–µ –Ω–∞–¥–æü§ô üëç üëç ...  positive   \n",
            "5   –ø—É—à–∫–∞ –Ω–∞ –∫–∞—Ä–∞—É–ª—å–Ω–æ–π –≥–æ—Ä–µ –±–æ–ª—å—à–µ –Ω–µ —Å—Ç—Ä–µ–ª—è–µ—Ç –±...  negative   \n",
            "6                    –∫–∞–∫ –º–∏–ª–æ  —Å–º—É—Ç–∏–ª–∞—Å—å  —Å–ø–∞—Å–∏–±–æ ü•∞üå∏  positive   \n",
            "9        –º–Ω–µ –±–æ–ª—å–Ω–æ –¥—ã—à–∞—Ç—å  —è –∫–∞–∫ –±–∞–±–∫–∞ 80 –ª–µ—Ç —É–∂–∞—Åüö¨  negative   \n",
            "\n",
            "                    id  \n",
            "1  1218052288964632576  \n",
            "2  1212859589592539136  \n",
            "5  1342696727808274432  \n",
            "6  1317052132382679041  \n",
            "9  1318122321622818816  \n"
          ]
        }
      ],
      "source": [
        "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞\n",
        "def preprocess(text):\n",
        "    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç—ã\n",
        "    text = re.sub(r'^(@\\w+\\s)+', '', text)\n",
        "\n",
        "    # –£–¥–∞–ª–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–≤–∏—Ç—ã\n",
        "    text = re.sub(r'https://t.co/\\w+', '', text)\n",
        "\n",
        "    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É\n",
        "    text = text.lower()\n",
        "\n",
        "    # –ó–∞–º–µ–Ω–∞ –≤—Å–µ—Ö \"—ë\" –Ω–∞ \"–µ\"\n",
        "    text = text.replace('—ë', '–µ')\n",
        "\n",
        "    # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ø–µ—Ü—Å–∏–º–æ–≤–ª–æ–≤, –∫—Ä–æ–º–µ !,? –∏ —ç–º–æ–¥–∑–∏\n",
        "    text = re.sub(r'[^\\w\\s\\p{So}!?]', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "preprocessed_train_data = filtered_train_data.copy()\n",
        "preprocessed_train_data['text'] = preprocessed_train_data['text'].apply(preprocess)\n",
        "print(preprocessed_train_data.head())\n",
        "\n",
        "preprocessed_test_data = filtered_test_data.copy()\n",
        "preprocessed_test_data['text'] = preprocessed_test_data['text'].apply(preprocess)\n",
        "print(preprocessed_test_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f574ec9",
      "metadata": {
        "id": "6f574ec9"
      },
      "outputs": [],
      "source": [
        "# –°—Ç–µ–º–º–∏–Ω–≥\n",
        "def stemming(text):\n",
        "    stemmer = SnowballStemmer(\"russian\")\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words] # +—É–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤\n",
        "    stemmed_text = ' '.join(stemmed_tokens)\n",
        "\n",
        "    return stemmed_text\n",
        "\n",
        "# –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è\n",
        "def lemmatization(text):\n",
        "    mystem = Mystem()\n",
        "    lemmas = mystem.lemmatize(text)\n",
        "\n",
        "    lemmas = [lemma.strip() for lemma in lemmas if lemma.isalnum()]\n",
        "    lemmatized_text = ' '.join(lemmas)\n",
        "\n",
        "    return lemmatized_text\n",
        "\n",
        "transformed_train_data = preprocessed_train_data.copy()\n",
        "#transformed_train_data['text'] = transformed_test_data['text'].apply(stemming)\n",
        "transformed_train_data['text'] = transformed_train_data['text'].apply(lemmatization)\n",
        "print(transformed_train_data.head())\n",
        "\n",
        "\n",
        "transformed_test_data = preprocessed_test_data.copy()\n",
        "#transformed_test_data['text'] = transformed_test_data['text'].apply(stemming)\n",
        "transformed_test_data['text'] = transformed_test_data['text'].apply(lemmatization)\n",
        "print(transformed_test_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c490c2",
      "metadata": {
        "id": "b6c490c2",
        "outputId": "1cda3711-7dc3-43d4-f56b-e75cae97c223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 4915)\t1\n",
            "  (0, 1005)\t1\n",
            "  (0, 7348)\t1\n",
            "  (1, 4989)\t1\n",
            "  (2, 6028)\t1\n",
            "  (2, 799)\t1\n",
            "  (2, 4649)\t1\n",
            "  (2, 2129)\t1\n",
            "  (2, 4797)\t1\n",
            "  (2, 6812)\t1\n",
            "  (3, 6817)\t2\n",
            "  (3, 1365)\t1\n",
            "  (3, 4832)\t1\n",
            "  (3, 5878)\t1\n",
            "  (3, 6847)\t1\n",
            "  (4, 6281)\t1\n",
            "  (4, 652)\t1\n",
            "  (5, 4897)\t1\n",
            "  (5, 404)\t1\n",
            "  (5, 5520)\t1\n",
            "  (5, 1350)\t1\n",
            "  (5, 4673)\t1\n",
            "  (6, 4544)\t1\n",
            "  (6, 7303)\t1\n",
            "  (6, 1086)\t1\n",
            "  :\t:\n",
            "  (4563, 7044)\t1\n",
            "  (4564, 5971)\t1\n",
            "  (4564, 6528)\t1\n",
            "  (4564, 3370)\t1\n",
            "  (4564, 6807)\t1\n",
            "  (4564, 2967)\t1\n",
            "  (4564, 7219)\t1\n",
            "  (4564, 4518)\t1\n",
            "  (4564, 4267)\t1\n",
            "  (4564, 1599)\t1\n",
            "  (4565, 3115)\t1\n",
            "  (4565, 1604)\t1\n",
            "  (4566, 6967)\t1\n",
            "  (4566, 7181)\t1\n",
            "  (4566, 1729)\t1\n",
            "  (4567, 2091)\t1\n",
            "  (4567, 3849)\t1\n",
            "  (4567, 6946)\t1\n",
            "  (4567, 1171)\t1\n",
            "  (4568, 492)\t1\n",
            "  (4568, 6532)\t1\n",
            "  (4568, 3653)\t1\n",
            "  (4568, 5038)\t1\n",
            "  (4568, 2348)\t1\n",
            "  (4568, 6921)\t1 \n",
            "\n",
            "\n",
            "  (0, 1404)\t1\n",
            "  (0, 3263)\t1\n",
            "  (0, 7561)\t1\n",
            "  (1, 5765)\t1\n",
            "  (1, 5938)\t1\n",
            "  (1, 6195)\t1\n",
            "  (1, 6528)\t1\n",
            "  (1, 7365)\t1\n",
            "  (1, 7561)\t1\n",
            "  (1, 7613)\t1\n",
            "  (2, 519)\t1\n",
            "  (2, 1430)\t1\n",
            "  (3, 3307)\t1\n",
            "  (3, 6089)\t1\n",
            "  (3, 6223)\t1\n",
            "  (4, 108)\t1\n",
            "  (4, 522)\t1\n",
            "  (4, 741)\t1\n",
            "  (4, 3018)\t1\n",
            "  (4, 6831)\t1\n",
            "  (5, 3119)\t1\n",
            "  (6, 1477)\t1\n",
            "  (6, 3093)\t1\n",
            "  (6, 3490)\t1\n",
            "  (10, 744)\t2\n",
            "  :\t:\n",
            "  (1136, 7303)\t1\n",
            "  (1136, 7561)\t1\n",
            "  (1137, 937)\t1\n",
            "  (1137, 1716)\t1\n",
            "  (1137, 1725)\t1\n",
            "  (1137, 2106)\t1\n",
            "  (1137, 3500)\t1\n",
            "  (1137, 3825)\t1\n",
            "  (1137, 4601)\t1\n",
            "  (1137, 5722)\t1\n",
            "  (1137, 5946)\t1\n",
            "  (1137, 6967)\t1\n",
            "  (1137, 7205)\t1\n",
            "  (1138, 803)\t1\n",
            "  (1138, 2529)\t1\n",
            "  (1138, 4608)\t1\n",
            "  (1138, 5388)\t1\n",
            "  (1138, 6047)\t1\n",
            "  (1138, 7561)\t2\n",
            "  (1140, 3638)\t1\n",
            "  (1140, 3824)\t1\n",
            "  (1140, 3891)\t1\n",
            "  (1141, 674)\t1\n",
            "  (1141, 3192)\t1\n",
            "  (1141, 6490)\t1\n"
          ]
        }
      ],
      "source": [
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –º–µ—à–æ–∫ —Å–ª–æ–≤\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_counts = vectorizer.fit_transform(transformed_train_data['text'])\n",
        "X_test_counts = vectorizer.transform(transformed_test_data['text'])\n",
        "print(X_train_counts, '\\n\\n')\n",
        "print(X_test_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d05844a",
      "metadata": {
        "id": "1d05844a",
        "outputId": "3f63dc23-2fb7-4a2c-ede8-c1323d6d15a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 7348)\t0.5862800063736923\n",
            "  (0, 4915)\t0.5862800063736923\n",
            "  (0, 1005)\t0.5590630628586786\n",
            "  (1, 4989)\t1.0\n",
            "  (2, 6812)\t0.39960587207917836\n",
            "  (2, 6028)\t0.3874703830260081\n",
            "  (2, 4797)\t0.43730214415327695\n",
            "  (2, 4649)\t0.4749984162273756\n",
            "  (2, 2129)\t0.43730214415327695\n",
            "  (2, 799)\t0.2865170558568824\n",
            "  (3, 6847)\t0.3339688054438098\n",
            "  (3, 6817)\t0.7197954718835435\n",
            "  (3, 5878)\t0.36731329848813576\n",
            "  (3, 4832)\t0.2737034718166318\n",
            "  (3, 1365)\t0.4006577915324617\n",
            "  (4, 6281)\t0.7291126923545203\n",
            "  (4, 652)\t0.6843936599995228\n",
            "  (5, 5520)\t0.38995284350726117\n",
            "  (5, 4897)\t0.455849472563417\n",
            "  (5, 4673)\t0.47804165475242977\n",
            "  (5, 1350)\t0.47804165475242977\n",
            "  (5, 404)\t0.42789062953910717\n",
            "  (6, 7383)\t0.2849251350148732\n",
            "  (6, 7303)\t0.2912726381861287\n",
            "  (6, 6709)\t0.41708449874405545\n",
            "  :\t:\n",
            "  (4563, 1897)\t0.27216802024634523\n",
            "  (4564, 7219)\t0.34707989812458057\n",
            "  (4564, 6807)\t0.3542313537634815\n",
            "  (4564, 6528)\t0.27241383860907425\n",
            "  (4564, 5971)\t0.25680400622549443\n",
            "  (4564, 4518)\t0.373041946989584\n",
            "  (4564, 4267)\t0.3863882752805229\n",
            "  (4564, 3370)\t0.21225733940437713\n",
            "  (4564, 2967)\t0.3408850254725426\n",
            "  (4564, 1599)\t0.40519886850662534\n",
            "  (4565, 3115)\t0.5595950583288255\n",
            "  (4565, 1604)\t0.8287661737148534\n",
            "  (4566, 7181)\t0.6193630902360009\n",
            "  (4566, 6967)\t0.44104286769217166\n",
            "  (4566, 1729)\t0.6495156282270481\n",
            "  (4567, 6946)\t0.5126611295066713\n",
            "  (4567, 3849)\t0.4336140103406786\n",
            "  (4567, 2091)\t0.4646182639126246\n",
            "  (4567, 1171)\t0.5773104235747322\n",
            "  (4568, 6921)\t0.4864123758327156\n",
            "  (4568, 6532)\t0.3457518986169296\n",
            "  (4568, 5038)\t0.4353831839580201\n",
            "  (4568, 3653)\t0.3480253183063563\n",
            "  (4568, 2348)\t0.4638315987055414\n",
            "  (4568, 492)\t0.3435676559662727 \n",
            "\n",
            "\n",
            "  (0, 7561)\t0.3253437016121291\n",
            "  (0, 3263)\t0.7684101352969448\n",
            "  (0, 1404)\t0.5510874157465844\n",
            "  (1, 7613)\t0.44194605778190904\n",
            "  (1, 7561)\t0.1715464134567471\n",
            "  (1, 7365)\t0.40516537471242187\n",
            "  (1, 6528)\t0.3115835281779999\n",
            "  (1, 6195)\t0.46346137812846855\n",
            "  (1, 5938)\t0.4148399598297655\n",
            "  (1, 5765)\t0.35654395641371883\n",
            "  (2, 1430)\t0.666941272540072\n",
            "  (2, 519)\t0.7451102864560584\n",
            "  (3, 6223)\t0.4608484581965721\n",
            "  (3, 6089)\t0.7376074066766156\n",
            "  (3, 3307)\t0.4935119169722654\n",
            "  (4, 6831)\t0.43287224606712027\n",
            "  (4, 3018)\t0.3726455959745171\n",
            "  (4, 741)\t0.4168463684733522\n",
            "  (4, 522)\t0.5127587298016383\n",
            "  (4, 108)\t0.48690293538691276\n",
            "  (5, 3119)\t1.0\n",
            "  (6, 3490)\t0.5348056153406485\n",
            "  (6, 3093)\t0.5974876374453744\n",
            "  (6, 1477)\t0.5974876374453744\n",
            "  (10, 6223)\t0.28415220436894006\n",
            "  :\t:\n",
            "  (1136, 6200)\t0.5727968074542831\n",
            "  (1136, 4085)\t0.49063872836078004\n",
            "  (1137, 7205)\t0.24560619485476573\n",
            "  (1137, 6967)\t0.25915917683497897\n",
            "  (1137, 5946)\t0.2663388025324409\n",
            "  (1137, 5722)\t0.3416193237319145\n",
            "  (1137, 4601)\t0.3159345405779161\n",
            "  (1137, 3825)\t0.2881434480999977\n",
            "  (1137, 3500)\t0.3113305538608725\n",
            "  (1137, 2106)\t0.3639411050164905\n",
            "  (1137, 1725)\t0.296627572403483\n",
            "  (1137, 1716)\t0.2789097778359506\n",
            "  (1137, 937)\t0.326916342274525\n",
            "  (1138, 7561)\t0.3919027975755995\n",
            "  (1138, 6047)\t0.4382298835816865\n",
            "  (1138, 5388)\t0.25698921284792775\n",
            "  (1138, 4608)\t0.4534626392981676\n",
            "  (1138, 2529)\t0.4534626392981676\n",
            "  (1138, 803)\t0.42079279983108386\n",
            "  (1140, 3891)\t0.5685894324324247\n",
            "  (1140, 3824)\t0.6419713882728918\n",
            "  (1140, 3638)\t0.5143722328869912\n",
            "  (1141, 6490)\t0.6803922733868949\n",
            "  (1141, 3192)\t0.5948098448061481\n",
            "  (1141, 674)\t0.4280976557248344\n"
          ]
        }
      ],
      "source": [
        "# –°–æ–∑–¥–∞–Ω–∏–µ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ TF-IDF –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ TF-IDF –º–∞—Ç—Ä–∏—Ü—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
        "\n",
        "print(X_train_tfidf, '\\n\\n')\n",
        "print(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "919713b1",
      "metadata": {
        "id": "919713b1",
        "outputId": "d70929e4-db0c-4a6f-896c-3d1e5bfe0c36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_mapping = {\"positive\": 1, \"negative\": 0}\n",
        "\n",
        "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –≤ —á–∏—Å–ª–µ–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç\n",
        "y_train_encoded = transformed_train_data['label'].map(label_mapping)\n",
        "y_test_encoded = transformed_test_data['label'].map(label_mapping)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(X_train_tfidf, y_train_encoded)\n",
        "\n",
        "# –û–±—É—á–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ª–µ—Å–∞\n",
        "random_forest = RandomForestClassifier()\n",
        "random_forest.fit(X_train_tfidf, y_train_encoded)\n",
        "\n",
        "y_train_pred_lr = logistic_regression.predict(X_train_tfidf)\n",
        "y_train_pred_rf = random_forest.predict(X_train_tfidf)\n",
        "\n",
        "y_test_pred_lr = logistic_regression.predict(X_test_tfidf)\n",
        "y_test_pred_rf = random_forest.predict(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "356f0505",
      "metadata": {
        "id": "356f0505",
        "outputId": "fe72c081-46d3-4950-90fd-78fed01e399d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
            "\n",
            "–õ–æ–≥. —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
            "\n",
            "Accuracy =  0.9150798861895382\n",
            "ROC-AUC =  0.9031424949224359\n",
            "Precision =  0.9684274438372799\n",
            "Recall =  0.8259968928016572\n",
            "F1-–º–µ—Ä–∞ =  0.8915595304639463\n",
            "\n",
            "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å\n",
            "\n",
            "Accuracy =  0.9949660757277303\n",
            "ROC-AUC =  0.9955712411792905\n",
            "Precision =  0.9887295081967213\n",
            "Recall =  0.9994821336095288\n",
            "F1-–º–µ—Ä–∞ =  0.9940767447849601\n",
            "\n",
            "\n",
            "–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
            "\n",
            "–õ–æ–≥. —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
            "\n",
            "Accuracy =  0.7637795275590551\n",
            "ROC-AUC =  0.7332674571805007\n",
            "Precision =  0.8491803278688524\n",
            "Recall =  0.5362318840579711\n",
            "F1-–º–µ—Ä–∞ =  0.6573604060913706\n",
            "\n",
            "–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å\n",
            "\n",
            "Accuracy =  0.7165354330708661\n",
            "ROC-AUC =  0.7167890080933559\n",
            "Precision =  0.6485981308411215\n",
            "Recall =  0.7184265010351967\n",
            "F1-–º–µ—Ä–∞ =  0.6817288801571709\n",
            "\n",
            "Top 20 Important Features (Words) for Logistic Regression:\n",
            "['–ª—é–±–ª', '–±–ª—è—Ç', '–∫—Ä–∞—Å–∏–≤', '–ø–∏–∑–¥–µ—Ü', '–ª—É—á—à', '–∫—Ä—É—Ç', '–∫–ª–∞—Å—Å–Ω', '–ø—Ä–µ–∫—Ä–∞—Å–Ω', '–º–∏–ª', '–Ω–∞—Ö', '—Å—É–∫', '—Ö–æ—Ä–æ—à', '—Ä–∞–¥', '–≤–∞', '–Ω—Ä–∞–≤', '–ª—é–±–∏–º', '—Ö—É–π–Ω', '–æ–±–æ–∂–∞', '–≤–æ–æ–±—â', '–ª—é–±–æ–≤']\n",
            "\n",
            "Top 20 Important Features (Words) for Random Forest:\n",
            "['–ª—é–±–ª', '–∫—Ä–∞—Å–∏–≤', '–±–ª—è—Ç', '–ª—É—á—à', '–∫—Ä—É—Ç', '—ç—Ç', '–ø—Ä–µ–∫—Ä–∞—Å–Ω', '–ø–∏–∑–¥–µ—Ü', '–∫–ª–∞—Å—Å–Ω', '–º–∏–ª', '–Ω—Ä–∞–≤', '—Ö–æ—Ä–æ—à', '—Ä–∞–¥', '–≤–∞', '–Ω–∞—Ö', '–æ—á–µ–Ω', '—Å—É–∫', '–ª—é–±–∏–º', '–≤–æ–æ–±—â', '—Ö–æ—á']\n"
          ]
        }
      ],
      "source": [
        "# –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
        "print('–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞\\n')\n",
        "\n",
        "# –õ–æ–≥. —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "print('–õ–æ–≥. —Ä–µ–≥—Ä–µ—Å—Å–∏—è\\n')\n",
        "print('Accuracy = ', accuracy_score(y_train_encoded, y_train_pred_lr))\n",
        "print('ROC-AUC = ', roc_auc_score(y_train_encoded, y_train_pred_lr))\n",
        "print('Precision = ', precision_score(y_train_encoded, y_train_pred_lr))\n",
        "print('Recall = ', recall_score(y_train_encoded, y_train_pred_lr))\n",
        "print('F1-–º–µ—Ä–∞ = ', f1_score(y_train_encoded, y_train_pred_lr))\n",
        "\n",
        "# –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å\n",
        "print('\\n–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å\\n')\n",
        "print('Accuracy = ', accuracy_score(y_train_encoded, y_train_pred_rf))\n",
        "print('ROC-AUC = ', roc_auc_score(y_train_encoded, y_train_pred_rf))\n",
        "print('Precision = ', precision_score(y_train_encoded, y_train_pred_rf))\n",
        "print('Recall = ', recall_score(y_train_encoded, y_train_pred_rf))\n",
        "print('F1-–º–µ—Ä–∞ = ', f1_score(y_train_encoded, y_train_pred_rf))\n",
        "\n",
        "\n",
        "# –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞\n",
        "print('\\n\\n–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞\\n')\n",
        "\n",
        "# –õ–æ–≥. —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
        "print('–õ–æ–≥. —Ä–µ–≥—Ä–µ—Å—Å–∏—è\\n')\n",
        "print('Accuracy = ', accuracy_score(y_test_encoded, y_test_pred_lr))\n",
        "print('ROC-AUC = ', roc_auc_score(y_test_encoded, y_test_pred_lr))\n",
        "print('Precision = ', precision_score(y_test_encoded, y_test_pred_lr))\n",
        "print('Recall = ', recall_score(y_test_encoded, y_test_pred_lr))\n",
        "print('F1-–º–µ—Ä–∞ = ', f1_score(y_test_encoded, y_test_pred_lr))\n",
        "\n",
        "# –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å\n",
        "print('\\n–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å\\n')\n",
        "print('Accuracy = ', accuracy_score(y_test_encoded, y_test_pred_rf))\n",
        "print('ROC-AUC = ', roc_auc_score(y_test_encoded, y_test_pred_rf))\n",
        "print('Precision = ', precision_score(y_test_encoded, y_test_pred_rf))\n",
        "print('Recall = ', recall_score(y_test_encoded, y_test_pred_rf))\n",
        "print('F1-–º–µ—Ä–∞ = ', f1_score(y_test_encoded, y_test_pred_rf))\n",
        "\n",
        "coefficients = logistic_regression.coef_[0]\n",
        "indices_lr = abs(coefficients).argsort()[::-1]\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "top_n = 20\n",
        "top_features_lr = [feature_names[index] for index in indices_lr[:top_n]]\n",
        "print(f\"\\nTop {top_n} Important Features (Words) for Logistic Regression:\")\n",
        "print(top_features_lr)\n",
        "\n",
        "feature_importances = random_forest.feature_importances_\n",
        "indices_rf = feature_importances.argsort()[::-1]\n",
        "top_features_rf = [feature_names[index] for index in indices_rf[:top_n]]\n",
        "print(f\"\\nTop {top_n} Important Features (Words) for Random Forest:\")\n",
        "print(top_features_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf10038f",
      "metadata": {
        "id": "bf10038f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}